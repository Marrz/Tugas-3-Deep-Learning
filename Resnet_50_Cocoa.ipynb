{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Resnet-50 Cocoa.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "doE6m1OiuRKY",
        "colab_type": "code",
        "outputId": "089c74f6-716f-4ec9-9b1c-c6581be454cf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        }
      },
      "source": [
        "import numpy as np\n",
        "import pickle\n",
        "import cv2\n",
        "from os import listdir\n",
        "from sklearn.preprocessing import LabelBinarizer\n",
        "from keras.models import Sequential\n",
        "from keras.layers.normalization import BatchNormalization\n",
        "from keras.layers.convolutional import Conv2D\n",
        "from keras.layers.convolutional import MaxPooling2D\n",
        "from keras.layers.core import Activation, Flatten, Dropout, Dense\n",
        "from keras import backend as K\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.optimizers import Adam\n",
        "from keras.preprocessing import image\n",
        "from keras.preprocessing.image import img_to_array\n",
        "from sklearn.preprocessing import MultiLabelBinarizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from tensorflow.python.keras.applications import ResNet50\n",
        "from tensorflow.python.keras.models import Sequential\n",
        "from tensorflow.python.keras.layers import Dense, Flatten, GlobalAveragePooling2D, BatchNormalization\n",
        "from keras_applications.resnet import preprocess_input\n",
        "from tensorflow.python.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.python.keras.preprocessing.image import load_img, img_to_array\n",
        "\n",
        "resnet_weights_path = '/content/drive/My Drive/Colab Notebooks/Tugas 3 Deep Learning/Resnet-50 Model/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5'"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ymp65NPpEFnY",
        "colab_type": "code",
        "outputId": "c825a723-e38d-43ba-9359-ff587cc61476",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "import numpy as np\n",
        "from keras import layers\n",
        "from keras.layers import Input, Add, Dense, Activation, ZeroPadding2D, BatchNormalization, Flatten, Conv2D, AveragePooling2D, MaxPooling2D, GlobalMaxPooling2D\n",
        "from keras.models import Model, load_model\n",
        "from keras.preprocessing import image\n",
        "from keras.utils import layer_utils\n",
        "from keras.utils.data_utils import get_file\n",
        "from keras.applications.imagenet_utils import preprocess_input\n",
        "import pydot\n",
        "from IPython.display import SVG\n",
        "from keras.utils.vis_utils import model_to_dot\n",
        "from keras.utils import plot_model\n",
        "#from resnets_utils import *\n",
        "from keras.initializers import glorot_uniform\n",
        "import scipy.misc\n",
        "from matplotlib.pyplot import imshow\n",
        "%matplotlib inline\n",
        "\n",
        "import keras.backend as K\n",
        "K.set_image_data_format('channels_last')\n",
        "K.set_learning_phase(1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dQ95E-mFxTaP",
        "colab_type": "code",
        "outputId": "aa323ee1-1bab-4ff9-e6b3-ad390068a687",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q9_susboxV54",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "EPOCHS = 100\n",
        "INIT_LR = 1e-3\n",
        "BS = 32\n",
        "default_image_size = tuple((224, 224))\n",
        "image_size = 0\n",
        "directory_root = '/content/drive/My Drive/Colab Notebooks/Tugas 3 Deep Learning/Dataset Coklat'\n",
        "width=224\n",
        "height=224\n",
        "depth=3"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tkLlsJY-xXQo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def convert_image_to_array(image_dir):\n",
        "    try:\n",
        "        image = cv2.imread(image_dir)\n",
        "        if image is not None :\n",
        "            image = cv2.resize(image, default_image_size)   \n",
        "            return img_to_array(image)\n",
        "        else :\n",
        "            return np.array([])\n",
        "    except Exception as e:\n",
        "        print(f\"Error : {e}\")\n",
        "        return None"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yIANL3-IxZvv",
        "colab_type": "code",
        "outputId": "fc11eaf9-8cf7-4ebb-cbbe-98660a72f1a7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        }
      },
      "source": [
        "image_list, label_list = [], []\n",
        "try:\n",
        "    print(\"[INFO] Loading images ...\")\n",
        "    root_dir = listdir(directory_root)\n",
        "    for directory in root_dir :\n",
        "        # remove .DS_Store from list\n",
        "        if directory == \".DS_Store\" :\n",
        "            root_dir.remove(directory)\n",
        "\n",
        "    for plant_folder in root_dir :\n",
        "        plant_disease_folder_list = listdir(f\"{directory_root}/{plant_folder}\")\n",
        "        \n",
        "        for disease_folder in plant_disease_folder_list :\n",
        "            # remove .DS_Store from list\n",
        "            if disease_folder == \".DS_Store\" :\n",
        "                plant_disease_folder_list.remove(disease_folder)\n",
        "\n",
        "        for plant_disease_folder in plant_disease_folder_list:\n",
        "            print(f\"[INFO] Processing {plant_disease_folder} ...\")\n",
        "            plant_disease_image_list = listdir(f\"{directory_root}/{plant_folder}/{plant_disease_folder}\")\n",
        "                \n",
        "            for single_plant_disease_image in plant_disease_image_list :\n",
        "                if single_plant_disease_image == \".DS_Store\" :\n",
        "                    plant_disease_image_list.remove(single_plant_disease_image)\n",
        "\n",
        "            for image in plant_disease_image_list[:200]:\n",
        "                image_directory = f\"{directory_root}/{plant_folder}/{plant_disease_folder}/{image}\"\n",
        "                if image_directory.endswith(\".jpg\") == True or image_directory.endswith(\".JPG\") == True:\n",
        "                    image_list.append(convert_image_to_array(image_directory))\n",
        "                    label_list.append(plant_disease_folder)\n",
        "    print(\"[INFO] Image loading completed\")  \n",
        "except Exception as e:\n",
        "    print(f\"Error : {e}\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[INFO] Loading images ...\n",
            "[INFO] Processing Moldy_Cocoa ...\n",
            "[INFO] Processing Broken_Beans_Cocoa ...\n",
            "[INFO] Processing Fermented_Cocoa ...\n",
            "[INFO] Processing Unfermented_Cocoa ...\n",
            "[INFO] Processing Bean_Fraction_Cocoa ...\n",
            "[INFO] Processing Whole_Beans_Cocoa ...\n",
            "[INFO] Image loading completed\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FNy0qr8bxbtR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "image_size = len(image_list)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P8nR0KeUxgGB",
        "colab_type": "code",
        "outputId": "ed06c07d-f10a-42c1-9d62-7f995ade9e23",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(image_size)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "614\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F2iiAjlBxdWj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "label_binarizer = LabelBinarizer()\n",
        "image_labels = label_binarizer.fit_transform(label_list)\n",
        "pickle.dump(label_binarizer,open('label_transform.pkl', 'wb'))\n",
        "n_classes = len(label_binarizer.classes_)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qmTK3lT3xe5p",
        "colab_type": "code",
        "outputId": "cf67b253-13f5-477e-9dc3-d4a5d6e06cf3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "print(label_binarizer.classes_)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['Bean_Fraction_Cocoa' 'Broken_Beans_Cocoa' 'Fermented_Cocoa'\n",
            " 'Moldy_Cocoa' 'Unfermented_Cocoa' 'Whole_Beans_Cocoa']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jzIfnWZrxjNr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "np_image_list = np.array(image_list, dtype=np.float16) / 225.0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xV8iuz6SxlGz",
        "colab_type": "code",
        "outputId": "fc813b85-0e13-4a9c-c2c3-fa32e3efe066",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(\"[INFO] Spliting data to train, test\")\n",
        "x_train, x_test, y_train, y_test = train_test_split(np_image_list, image_labels, test_size=0.2, random_state = 42) "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[INFO] Spliting data to train, test\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1fyAdsIIxmJL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "aug = ImageDataGenerator(\n",
        "    rotation_range=25, width_shift_range=0.1,\n",
        "    height_shift_range=0.1, shear_range=0.2, \n",
        "    zoom_range=0.2,horizontal_flip=True, \n",
        "    fill_mode=\"nearest\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TTUxd2si_KXa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# GRADED FUNCTION: identity_block\n",
        "\n",
        "def identity_block(X, f, filters, stage, block):\n",
        "    \"\"\"\n",
        "    Implementation of the identity block as defined in Figure 3\n",
        "    \n",
        "    Arguments:\n",
        "    X -- input tensor of shape (m, n_H_prev, n_W_prev, n_C_prev)\n",
        "    f -- integer, specifying the shape of the middle CONV's window for the main path\n",
        "    filters -- python list of integers, defining the number of filters in the CONV layers of the main path\n",
        "    stage -- integer, used to name the layers, depending on their position in the network\n",
        "    block -- string/character, used to name the layers, depending on their position in the network\n",
        "    \n",
        "    Returns:\n",
        "    X -- output of the identity block, tensor of shape (n_H, n_W, n_C)\n",
        "    \"\"\"\n",
        "    \n",
        "    # defining name basis\n",
        "    conv_name_base = 'res' + str(stage) + block + '_branch'\n",
        "    bn_name_base = 'bn' + str(stage) + block + '_branch'\n",
        "    \n",
        "    # Retrieve Filters\n",
        "    F1, F2, F3 = filters\n",
        "    \n",
        "    # Save the input value. You'll need this later to add back to the main path. \n",
        "    X_shortcut = X\n",
        "    \n",
        "    # First component of main path\n",
        "    X = Conv2D(filters = F1, kernel_size = (1, 1), strides = (1,1), padding = 'valid', name = conv_name_base + '2a', kernel_initializer = glorot_uniform(seed=0))(X)\n",
        "    X = BatchNormalization(axis = 3, name = bn_name_base + '2a')(X)\n",
        "    X = Activation('relu')(X)\n",
        "    \n",
        "    ### START CODE HERE ###\n",
        "    \n",
        "    # Second component of main path (≈3 lines)\n",
        "    X = Conv2D(F2,kernel_size=(f,f),strides=(1,1),padding='same',kernel_initializer = glorot_uniform(seed=0))(X)\n",
        "    X = BatchNormalization(axis=-1)(X)\n",
        "    X = Activation('relu')(X)\n",
        "\n",
        "    # Third component of main path (≈2 lines)\n",
        "    X = Conv2D(F3,(1,1),strides=(1,1),padding='valid',kernel_initializer = glorot_uniform(seed=0))(X)\n",
        "    X = BatchNormalization(axis=-1)(X)\n",
        "\n",
        "    # Final step: Add shortcut value to main path, and pass it through a RELU activation (≈2 lines)\n",
        "    X = Add()([X,X_shortcut])\n",
        "    X = Activation('relu')(X)\n",
        "    \n",
        "    ### END CODE HERE ###\n",
        "    \n",
        "    return X"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jbLvi9nWDQx_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def convolutional_block(X, f, filters, stage, block, s = 2):\n",
        "    \"\"\"\n",
        "    Implementation of the convolutional block as defined in Figure 4\n",
        "    \n",
        "    Arguments:\n",
        "    X -- input tensor of shape (m, n_H_prev, n_W_prev, n_C_prev)\n",
        "    f -- integer, specifying the shape of the middle CONV's window for the main path\n",
        "    filters -- python list of integers, defining the number of filters in the CONV layers of the main path\n",
        "    stage -- integer, used to name the layers, depending on their position in the network\n",
        "    block -- string/character, used to name the layers, depending on their position in the network\n",
        "    s -- Integer, specifying the stride to be used\n",
        "    \n",
        "    Returns:\n",
        "    X -- output of the convolutional block, tensor of shape (n_H, n_W, n_C)\n",
        "    \"\"\"\n",
        "    \n",
        "    # defining name basis\n",
        "    conv_name_base = 'res' + str(stage) + block + '_branch'\n",
        "    bn_name_base = 'bn' + str(stage) + block + '_branch'\n",
        "    \n",
        "    # Retrieve Filters\n",
        "    F1, F2, F3 = filters\n",
        "    \n",
        "    # Save the input value\n",
        "    X_shortcut = X\n",
        "\n",
        "\n",
        "    ##### MAIN PATH #####\n",
        "    # First component of main path \n",
        "    X = Conv2D(filters =F1, kernel_size =(1, 1), strides = (s,s), padding = 'valid', name = conv_name_base + '2a', kernel_initializer = glorot_uniform(seed=0))(X)\n",
        "    X = BatchNormalization(axis = 3, name = bn_name_base + '2a')(X)\n",
        "    X = Activation('relu')(X)\n",
        "    \n",
        "    ### START CODE HERE ###\n",
        "\n",
        "    # Second component of main path (≈3 lines)\n",
        "    X = Conv2D(filters =F2, kernel_size =(f, f), strides = (1,1), padding = 'same', name = conv_name_base + '2b', kernel_initializer = glorot_uniform(seed=0))(X)\n",
        "    X = BatchNormalization(axis = 3, name = bn_name_base + '2b')(X)\n",
        "    X = Activation('relu')(X)\n",
        "\n",
        "    # Third component of main path (≈2 lines)\n",
        "    X = Conv2D(filters =F3, kernel_size =(1, 1), strides = (1,1), padding = 'valid', name = conv_name_base + '2c', kernel_initializer = glorot_uniform(seed=0))(X)\n",
        "    X = BatchNormalization(axis = 3, name = bn_name_base + '2c')(X)\n",
        "\n",
        "    ##### SHORTCUT PATH #### (≈2 lines)\n",
        "    X_shortcut = Conv2D(filters =F3, kernel_size =(1, 1), strides = (s,s), padding = 'valid', name = conv_name_base + '1', kernel_initializer = glorot_uniform(seed=0))(X_shortcut)\n",
        "    X_shortcut = BatchNormalization(axis = 3, name = bn_name_base + '1')(X_shortcut)\n",
        "\n",
        "    # Final step: Add shortcut value to main path, and pass it through a RELU activation (≈2 lines)\n",
        "    X = Add()([X, X_shortcut]) \n",
        "    X = Activation('relu')(X)\n",
        "    \n",
        "    ### END CODE HERE ###\n",
        "    \n",
        "    return X"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UfTR3VBKxrHa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# GRADED FUNCTION: ResNet50\n",
        "\n",
        "def ResNet50(input_shape = (64, 64, 3), classes = 6):\n",
        "    \"\"\"\n",
        "    Implementation of the popular ResNet50 the following architecture:\n",
        "    CONV2D -> BATCHNORM -> RELU -> MAXPOOL -> CONVBLOCK -> IDBLOCK*2 -> CONVBLOCK -> IDBLOCK*3\n",
        "    -> CONVBLOCK -> IDBLOCK*5 -> CONVBLOCK -> IDBLOCK*2 -> AVGPOOL -> TOPLAYER\n",
        "\n",
        "    Arguments:\n",
        "    input_shape -- shape of the images of the dataset\n",
        "    classes -- integer, number of classes\n",
        "\n",
        "    Returns:\n",
        "    model -- a Model() instance in Keras\n",
        "    \"\"\"\n",
        "    \n",
        "    # Define the input as a tensor with shape input_shape\n",
        "    X_input = Input(input_shape)\n",
        "\n",
        "    \n",
        "    # Zero-Padding\n",
        "    X = ZeroPadding2D((3, 3))(X_input)\n",
        "    \n",
        "    # Stage 1\n",
        "    X = Conv2D(64, (7, 7), strides = (2, 2), name = 'conv1', kernel_initializer = glorot_uniform(seed=0))(X)\n",
        "    X = BatchNormalization(axis = 3, name = 'bn_conv1')(X)\n",
        "    X = Activation('relu')(X)\n",
        "    X = MaxPooling2D((3, 3), strides=(2, 2))(X)\n",
        "\n",
        "    # Stage 2\n",
        "    X = convolutional_block(X, f = 3, filters = [64, 64, 256], stage = 2, block='a', s = 1)\n",
        "    X = identity_block(X, 3, [64, 64, 256], stage=2, block='b')\n",
        "    X = identity_block(X, 3, [64, 64, 256], stage=2, block='c')\n",
        "\n",
        "    ### START CODE HERE ###\n",
        "\n",
        "    # Stage 3 (≈4 lines)\n",
        "    X = convolutional_block(X, f = 3, filters = [128, 128, 512], stage = 3, block='a', s = 2)\n",
        "    X = identity_block(X, 3, [128, 128, 512], stage=3, block='b')\n",
        "    X = identity_block(X, 3, [128, 128, 512], stage=3, block='c')\n",
        "    X = identity_block(X, 3, [128, 128, 512], stage=3, block='d')\n",
        "\n",
        "    # Stage 4 (≈6 lines)\n",
        "    X = convolutional_block(X, f = 3, filters = [256, 256, 1024], stage = 4, block='a', s = 2)\n",
        "    X = identity_block(X, 3, [256, 256, 1024], stage=4, block='b')\n",
        "    X = identity_block(X, 3, [256, 256, 1024], stage=4, block='c')\n",
        "    X = identity_block(X, 3, [256, 256, 1024], stage=4, block='d')\n",
        "    X = identity_block(X, 3, [256, 256, 1024], stage=4, block='e')\n",
        "    X = identity_block(X, 3, [256, 256, 1024], stage=4, block='f')\n",
        "\n",
        "    # Stage 5 (≈3 lines)\n",
        "    X = convolutional_block(X, f = 3, filters = [512, 512, 2048], stage = 5, block='a', s = 2)\n",
        "    X = identity_block(X, 3, [512, 512, 2048], stage=5, block='b')\n",
        "    X = identity_block(X, 3, [512, 512, 2048], stage=5, block='c')\n",
        "\n",
        "    # AVGPOOL (≈1 line). Use \"X = AveragePooling2D(...)(X)\"\n",
        "    X = AveragePooling2D(pool_size=(2, 2), name = 'avg_pool')(X)\n",
        "    \n",
        "    ### END CODE HERE ###\n",
        "\n",
        "    # output layer\n",
        "    X = Flatten()(X)\n",
        "    X = Dense(classes, activation='softmax', name='fc' + str(classes), kernel_initializer = glorot_uniform(seed=0))(X)\n",
        "    \n",
        "    \n",
        "    # Create model\n",
        "    model = Model(inputs = X_input, outputs = X, name='ResNet50')\n",
        "\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wxaQLFLd1OZn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W4vLHZJUDVId",
        "colab_type": "code",
        "outputId": "336419dc-0fdc-4d69-a4d9-09ee365a1df4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        }
      },
      "source": [
        "model = ResNet50(input_shape = (224, 224, 3), classes = 6)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:203: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:2041: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4267: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4271: The name tf.nn.avg_pool is deprecated. Please use tf.nn.avg_pool2d instead.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GbSxpmAQxv6J",
        "colab_type": "code",
        "outputId": "f6efc40b-d7c3-4848-9672-8a4d7239937b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "model.compile(optimizer='adam', loss=\"binary_crossentropy\", metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3657: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n",
            "WARNING:tensorflow:From /tensorflow-1.15.0/python3.6/tensorflow_core/python/ops/nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YSr9RBGtxzp2",
        "colab_type": "code",
        "outputId": "26af36f0-7026-4aea-d925-94a8d20e38f3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"ResNet50\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            (None, 224, 224, 3)  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "zero_padding2d_1 (ZeroPadding2D (None, 230, 230, 3)  0           input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv1 (Conv2D)                  (None, 112, 112, 64) 9472        zero_padding2d_1[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "bn_conv1 (BatchNormalization)   (None, 112, 112, 64) 256         conv1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "activation_1 (Activation)       (None, 112, 112, 64) 0           bn_conv1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2D)  (None, 55, 55, 64)   0           activation_1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "res2a_branch2a (Conv2D)         (None, 55, 55, 64)   4160        max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "bn2a_branch2a (BatchNormalizati (None, 55, 55, 64)   256         res2a_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_2 (Activation)       (None, 55, 55, 64)   0           bn2a_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2a_branch2b (Conv2D)         (None, 55, 55, 64)   36928       activation_2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "bn2a_branch2b (BatchNormalizati (None, 55, 55, 64)   256         res2a_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_3 (Activation)       (None, 55, 55, 64)   0           bn2a_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2a_branch2c (Conv2D)         (None, 55, 55, 256)  16640       activation_3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "res2a_branch1 (Conv2D)          (None, 55, 55, 256)  16640       max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "bn2a_branch2c (BatchNormalizati (None, 55, 55, 256)  1024        res2a_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn2a_branch1 (BatchNormalizatio (None, 55, 55, 256)  1024        res2a_branch1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_1 (Add)                     (None, 55, 55, 256)  0           bn2a_branch2c[0][0]              \n",
            "                                                                 bn2a_branch1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "activation_4 (Activation)       (None, 55, 55, 256)  0           add_1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res2b_branch2a (Conv2D)         (None, 55, 55, 64)   16448       activation_4[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "bn2b_branch2a (BatchNormalizati (None, 55, 55, 64)   256         res2b_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_5 (Activation)       (None, 55, 55, 64)   0           bn2b_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1 (Conv2D)               (None, 55, 55, 64)   36928       activation_5[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1 (BatchNor (None, 55, 55, 64)   256         conv2d_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_6 (Activation)       (None, 55, 55, 64)   0           batch_normalization_1[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_2 (Conv2D)               (None, 55, 55, 256)  16640       activation_6[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_2 (BatchNor (None, 55, 55, 256)  1024        conv2d_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "add_2 (Add)                     (None, 55, 55, 256)  0           batch_normalization_2[0][0]      \n",
            "                                                                 activation_4[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "activation_7 (Activation)       (None, 55, 55, 256)  0           add_2[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res2c_branch2a (Conv2D)         (None, 55, 55, 64)   16448       activation_7[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "bn2c_branch2a (BatchNormalizati (None, 55, 55, 64)   256         res2c_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_8 (Activation)       (None, 55, 55, 64)   0           bn2c_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_3 (Conv2D)               (None, 55, 55, 64)   36928       activation_8[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_3 (BatchNor (None, 55, 55, 64)   256         conv2d_3[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_9 (Activation)       (None, 55, 55, 64)   0           batch_normalization_3[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_4 (Conv2D)               (None, 55, 55, 256)  16640       activation_9[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_4 (BatchNor (None, 55, 55, 256)  1024        conv2d_4[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "add_3 (Add)                     (None, 55, 55, 256)  0           batch_normalization_4[0][0]      \n",
            "                                                                 activation_7[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "activation_10 (Activation)      (None, 55, 55, 256)  0           add_3[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res3a_branch2a (Conv2D)         (None, 28, 28, 128)  32896       activation_10[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3a_branch2a (BatchNormalizati (None, 28, 28, 128)  512         res3a_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_11 (Activation)      (None, 28, 28, 128)  0           bn3a_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3a_branch2b (Conv2D)         (None, 28, 28, 128)  147584      activation_11[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3a_branch2b (BatchNormalizati (None, 28, 28, 128)  512         res3a_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_12 (Activation)      (None, 28, 28, 128)  0           bn3a_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3a_branch2c (Conv2D)         (None, 28, 28, 512)  66048       activation_12[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3a_branch1 (Conv2D)          (None, 28, 28, 512)  131584      activation_10[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3a_branch2c (BatchNormalizati (None, 28, 28, 512)  2048        res3a_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn3a_branch1 (BatchNormalizatio (None, 28, 28, 512)  2048        res3a_branch1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_4 (Add)                     (None, 28, 28, 512)  0           bn3a_branch2c[0][0]              \n",
            "                                                                 bn3a_branch1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "activation_13 (Activation)      (None, 28, 28, 512)  0           add_4[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res3b_branch2a (Conv2D)         (None, 28, 28, 128)  65664       activation_13[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3b_branch2a (BatchNormalizati (None, 28, 28, 128)  512         res3b_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_14 (Activation)      (None, 28, 28, 128)  0           bn3b_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_5 (Conv2D)               (None, 28, 28, 128)  147584      activation_14[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_5 (BatchNor (None, 28, 28, 128)  512         conv2d_5[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_15 (Activation)      (None, 28, 28, 128)  0           batch_normalization_5[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_6 (Conv2D)               (None, 28, 28, 512)  66048       activation_15[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_6 (BatchNor (None, 28, 28, 512)  2048        conv2d_6[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "add_5 (Add)                     (None, 28, 28, 512)  0           batch_normalization_6[0][0]      \n",
            "                                                                 activation_13[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_16 (Activation)      (None, 28, 28, 512)  0           add_5[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res3c_branch2a (Conv2D)         (None, 28, 28, 128)  65664       activation_16[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3c_branch2a (BatchNormalizati (None, 28, 28, 128)  512         res3c_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_17 (Activation)      (None, 28, 28, 128)  0           bn3c_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_7 (Conv2D)               (None, 28, 28, 128)  147584      activation_17[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_7 (BatchNor (None, 28, 28, 128)  512         conv2d_7[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_18 (Activation)      (None, 28, 28, 128)  0           batch_normalization_7[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_8 (Conv2D)               (None, 28, 28, 512)  66048       activation_18[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_8 (BatchNor (None, 28, 28, 512)  2048        conv2d_8[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "add_6 (Add)                     (None, 28, 28, 512)  0           batch_normalization_8[0][0]      \n",
            "                                                                 activation_16[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_19 (Activation)      (None, 28, 28, 512)  0           add_6[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res3d_branch2a (Conv2D)         (None, 28, 28, 128)  65664       activation_19[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3d_branch2a (BatchNormalizati (None, 28, 28, 128)  512         res3d_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_20 (Activation)      (None, 28, 28, 128)  0           bn3d_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_9 (Conv2D)               (None, 28, 28, 128)  147584      activation_20[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_9 (BatchNor (None, 28, 28, 128)  512         conv2d_9[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_21 (Activation)      (None, 28, 28, 128)  0           batch_normalization_9[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_10 (Conv2D)              (None, 28, 28, 512)  66048       activation_21[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_10 (BatchNo (None, 28, 28, 512)  2048        conv2d_10[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_7 (Add)                     (None, 28, 28, 512)  0           batch_normalization_10[0][0]     \n",
            "                                                                 activation_19[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_22 (Activation)      (None, 28, 28, 512)  0           add_7[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res4a_branch2a (Conv2D)         (None, 14, 14, 256)  131328      activation_22[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4a_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4a_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_23 (Activation)      (None, 14, 14, 256)  0           bn4a_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4a_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_23[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4a_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4a_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_24 (Activation)      (None, 14, 14, 256)  0           bn4a_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4a_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_24[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4a_branch1 (Conv2D)          (None, 14, 14, 1024) 525312      activation_22[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4a_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4a_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn4a_branch1 (BatchNormalizatio (None, 14, 14, 1024) 4096        res4a_branch1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_8 (Add)                     (None, 14, 14, 1024) 0           bn4a_branch2c[0][0]              \n",
            "                                                                 bn4a_branch1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "activation_25 (Activation)      (None, 14, 14, 1024) 0           add_8[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res4b_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_25[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4b_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4b_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_26 (Activation)      (None, 14, 14, 256)  0           bn4b_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_11 (Conv2D)              (None, 14, 14, 256)  590080      activation_26[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_11 (BatchNo (None, 14, 14, 256)  1024        conv2d_11[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_27 (Activation)      (None, 14, 14, 256)  0           batch_normalization_11[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_12 (Conv2D)              (None, 14, 14, 1024) 263168      activation_27[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_12 (BatchNo (None, 14, 14, 1024) 4096        conv2d_12[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_9 (Add)                     (None, 14, 14, 1024) 0           batch_normalization_12[0][0]     \n",
            "                                                                 activation_25[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_28 (Activation)      (None, 14, 14, 1024) 0           add_9[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res4c_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_28[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4c_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4c_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_29 (Activation)      (None, 14, 14, 256)  0           bn4c_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_13 (Conv2D)              (None, 14, 14, 256)  590080      activation_29[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_13 (BatchNo (None, 14, 14, 256)  1024        conv2d_13[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_30 (Activation)      (None, 14, 14, 256)  0           batch_normalization_13[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_14 (Conv2D)              (None, 14, 14, 1024) 263168      activation_30[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_14 (BatchNo (None, 14, 14, 1024) 4096        conv2d_14[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_10 (Add)                    (None, 14, 14, 1024) 0           batch_normalization_14[0][0]     \n",
            "                                                                 activation_28[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_31 (Activation)      (None, 14, 14, 1024) 0           add_10[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res4d_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_31[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4d_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4d_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_32 (Activation)      (None, 14, 14, 256)  0           bn4d_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_15 (Conv2D)              (None, 14, 14, 256)  590080      activation_32[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_15 (BatchNo (None, 14, 14, 256)  1024        conv2d_15[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_33 (Activation)      (None, 14, 14, 256)  0           batch_normalization_15[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_16 (Conv2D)              (None, 14, 14, 1024) 263168      activation_33[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_16 (BatchNo (None, 14, 14, 1024) 4096        conv2d_16[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_11 (Add)                    (None, 14, 14, 1024) 0           batch_normalization_16[0][0]     \n",
            "                                                                 activation_31[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_34 (Activation)      (None, 14, 14, 1024) 0           add_11[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res4e_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_34[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4e_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4e_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_35 (Activation)      (None, 14, 14, 256)  0           bn4e_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_17 (Conv2D)              (None, 14, 14, 256)  590080      activation_35[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_17 (BatchNo (None, 14, 14, 256)  1024        conv2d_17[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_36 (Activation)      (None, 14, 14, 256)  0           batch_normalization_17[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_18 (Conv2D)              (None, 14, 14, 1024) 263168      activation_36[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_18 (BatchNo (None, 14, 14, 1024) 4096        conv2d_18[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_12 (Add)                    (None, 14, 14, 1024) 0           batch_normalization_18[0][0]     \n",
            "                                                                 activation_34[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_37 (Activation)      (None, 14, 14, 1024) 0           add_12[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res4f_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_37[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4f_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4f_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_38 (Activation)      (None, 14, 14, 256)  0           bn4f_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_19 (Conv2D)              (None, 14, 14, 256)  590080      activation_38[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_19 (BatchNo (None, 14, 14, 256)  1024        conv2d_19[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_39 (Activation)      (None, 14, 14, 256)  0           batch_normalization_19[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_20 (Conv2D)              (None, 14, 14, 1024) 263168      activation_39[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_20 (BatchNo (None, 14, 14, 1024) 4096        conv2d_20[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_13 (Add)                    (None, 14, 14, 1024) 0           batch_normalization_20[0][0]     \n",
            "                                                                 activation_37[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_40 (Activation)      (None, 14, 14, 1024) 0           add_13[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res5a_branch2a (Conv2D)         (None, 7, 7, 512)    524800      activation_40[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5a_branch2a (BatchNormalizati (None, 7, 7, 512)    2048        res5a_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_41 (Activation)      (None, 7, 7, 512)    0           bn5a_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5a_branch2b (Conv2D)         (None, 7, 7, 512)    2359808     activation_41[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5a_branch2b (BatchNormalizati (None, 7, 7, 512)    2048        res5a_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_42 (Activation)      (None, 7, 7, 512)    0           bn5a_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5a_branch2c (Conv2D)         (None, 7, 7, 2048)   1050624     activation_42[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5a_branch1 (Conv2D)          (None, 7, 7, 2048)   2099200     activation_40[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5a_branch2c (BatchNormalizati (None, 7, 7, 2048)   8192        res5a_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn5a_branch1 (BatchNormalizatio (None, 7, 7, 2048)   8192        res5a_branch1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_14 (Add)                    (None, 7, 7, 2048)   0           bn5a_branch2c[0][0]              \n",
            "                                                                 bn5a_branch1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "activation_43 (Activation)      (None, 7, 7, 2048)   0           add_14[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res5b_branch2a (Conv2D)         (None, 7, 7, 512)    1049088     activation_43[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5b_branch2a (BatchNormalizati (None, 7, 7, 512)    2048        res5b_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_44 (Activation)      (None, 7, 7, 512)    0           bn5b_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_21 (Conv2D)              (None, 7, 7, 512)    2359808     activation_44[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_21 (BatchNo (None, 7, 7, 512)    2048        conv2d_21[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_45 (Activation)      (None, 7, 7, 512)    0           batch_normalization_21[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_22 (Conv2D)              (None, 7, 7, 2048)   1050624     activation_45[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_22 (BatchNo (None, 7, 7, 2048)   8192        conv2d_22[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_15 (Add)                    (None, 7, 7, 2048)   0           batch_normalization_22[0][0]     \n",
            "                                                                 activation_43[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_46 (Activation)      (None, 7, 7, 2048)   0           add_15[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res5c_branch2a (Conv2D)         (None, 7, 7, 512)    1049088     activation_46[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5c_branch2a (BatchNormalizati (None, 7, 7, 512)    2048        res5c_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_47 (Activation)      (None, 7, 7, 512)    0           bn5c_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_23 (Conv2D)              (None, 7, 7, 512)    2359808     activation_47[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_23 (BatchNo (None, 7, 7, 512)    2048        conv2d_23[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_48 (Activation)      (None, 7, 7, 512)    0           batch_normalization_23[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_24 (Conv2D)              (None, 7, 7, 2048)   1050624     activation_48[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_24 (BatchNo (None, 7, 7, 2048)   8192        conv2d_24[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_16 (Add)                    (None, 7, 7, 2048)   0           batch_normalization_24[0][0]     \n",
            "                                                                 activation_46[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_49 (Activation)      (None, 7, 7, 2048)   0           add_16[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "avg_pool (AveragePooling2D)     (None, 3, 3, 2048)   0           activation_49[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "flatten_1 (Flatten)             (None, 18432)        0           avg_pool[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "fc6 (Dense)                     (None, 6)            110598      flatten_1[0][0]                  \n",
            "==================================================================================================\n",
            "Total params: 23,698,310\n",
            "Trainable params: 23,645,190\n",
            "Non-trainable params: 53,120\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SDlraN1bx1oH",
        "colab_type": "code",
        "outputId": "1e41674d-98b9-46ce-c87a-50b75d39cb21",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# Train model\n",
        "history = model.fit_generator(\n",
        "    aug.flow(x_train, y_train, batch_size=BS),\n",
        "    validation_data=(x_test, y_test),\n",
        "    epochs=EPOCHS,\n",
        "    steps_per_epoch=len(x_train) // BS,\n",
        "    verbose=1\n",
        "    )"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n",
            "Epoch 1/100\n",
            "15/15 [==============================] - 23s 2s/step - loss: 2.9881 - acc: 0.7484 - val_loss: 2.6853 - val_acc: 0.7317\n",
            "Epoch 2/100\n",
            "15/15 [==============================] - 6s 422ms/step - loss: 2.3473 - acc: 0.7201 - val_loss: 2.0773 - val_acc: 0.7317\n",
            "Epoch 3/100\n",
            "15/15 [==============================] - 6s 390ms/step - loss: 1.9182 - acc: 0.7307 - val_loss: 1.6018 - val_acc: 0.8198\n",
            "Epoch 4/100\n",
            "15/15 [==============================] - 6s 419ms/step - loss: 1.3198 - acc: 0.7826 - val_loss: 1.3462 - val_acc: 0.8171\n",
            "Epoch 5/100\n",
            "15/15 [==============================] - 6s 409ms/step - loss: 1.1687 - acc: 0.8167 - val_loss: 0.7393 - val_acc: 0.8306\n",
            "Epoch 6/100\n",
            "15/15 [==============================] - 6s 389ms/step - loss: 0.9055 - acc: 0.8113 - val_loss: 0.6627 - val_acc: 0.8198\n",
            "Epoch 7/100\n",
            "15/15 [==============================] - 6s 407ms/step - loss: 0.6219 - acc: 0.8274 - val_loss: 0.6853 - val_acc: 0.8225\n",
            "Epoch 8/100\n",
            "15/15 [==============================] - 6s 419ms/step - loss: 0.6012 - acc: 0.8368 - val_loss: 0.4840 - val_acc: 0.8333\n",
            "Epoch 9/100\n",
            "15/15 [==============================] - 6s 405ms/step - loss: 0.6142 - acc: 0.8340 - val_loss: 0.5565 - val_acc: 0.8415\n",
            "Epoch 10/100\n",
            "15/15 [==============================] - 6s 403ms/step - loss: 0.8774 - acc: 0.8215 - val_loss: 0.6429 - val_acc: 0.8401\n",
            "Epoch 11/100\n",
            "15/15 [==============================] - 6s 402ms/step - loss: 0.7322 - acc: 0.8343 - val_loss: 0.7363 - val_acc: 0.8333\n",
            "Epoch 12/100\n",
            "15/15 [==============================] - 6s 389ms/step - loss: 0.5663 - acc: 0.8496 - val_loss: 0.5538 - val_acc: 0.8564\n",
            "Epoch 13/100\n",
            "15/15 [==============================] - 6s 419ms/step - loss: 0.7016 - acc: 0.8399 - val_loss: 0.8589 - val_acc: 0.8238\n",
            "Epoch 14/100\n",
            "15/15 [==============================] - 6s 405ms/step - loss: 0.6992 - acc: 0.8420 - val_loss: 0.9586 - val_acc: 0.8496\n",
            "Epoch 15/100\n",
            "15/15 [==============================] - 6s 405ms/step - loss: 0.6485 - acc: 0.8514 - val_loss: 0.5494 - val_acc: 0.8537\n",
            "Epoch 16/100\n",
            "15/15 [==============================] - 6s 399ms/step - loss: 0.5859 - acc: 0.8429 - val_loss: 0.5858 - val_acc: 0.8415\n",
            "Epoch 17/100\n",
            "15/15 [==============================] - 6s 409ms/step - loss: 0.5497 - acc: 0.8472 - val_loss: 0.5041 - val_acc: 0.8591\n",
            "Epoch 18/100\n",
            "15/15 [==============================] - 6s 422ms/step - loss: 0.5237 - acc: 0.8632 - val_loss: 0.4223 - val_acc: 0.8740\n",
            "Epoch 19/100\n",
            "15/15 [==============================] - 6s 403ms/step - loss: 0.9742 - acc: 0.8230 - val_loss: 1.2890 - val_acc: 0.7846\n",
            "Epoch 20/100\n",
            "15/15 [==============================] - 6s 402ms/step - loss: 0.9220 - acc: 0.8228 - val_loss: 0.6593 - val_acc: 0.8415\n",
            "Epoch 21/100\n",
            "15/15 [==============================] - 6s 405ms/step - loss: 0.6573 - acc: 0.8414 - val_loss: 0.5519 - val_acc: 0.8591\n",
            "Epoch 22/100\n",
            "15/15 [==============================] - 6s 402ms/step - loss: 0.5720 - acc: 0.8504 - val_loss: 0.4916 - val_acc: 0.8550\n",
            "Epoch 23/100\n",
            "15/15 [==============================] - 6s 388ms/step - loss: 0.4994 - acc: 0.8662 - val_loss: 0.6208 - val_acc: 0.8537\n",
            "Epoch 24/100\n",
            "15/15 [==============================] - 6s 414ms/step - loss: 0.4853 - acc: 0.8642 - val_loss: 0.5184 - val_acc: 0.8496\n",
            "Epoch 25/100\n",
            "15/15 [==============================] - 6s 411ms/step - loss: 0.5145 - acc: 0.8673 - val_loss: 0.4954 - val_acc: 0.8699\n",
            "Epoch 26/100\n",
            "15/15 [==============================] - 6s 419ms/step - loss: 0.3544 - acc: 0.8708 - val_loss: 0.4682 - val_acc: 0.8740\n",
            "Epoch 27/100\n",
            "15/15 [==============================] - 6s 382ms/step - loss: 0.4249 - acc: 0.8732 - val_loss: 0.5043 - val_acc: 0.8659\n",
            "Epoch 28/100\n",
            "15/15 [==============================] - 6s 418ms/step - loss: 0.3554 - acc: 0.8781 - val_loss: 0.4761 - val_acc: 0.8753\n",
            "Epoch 29/100\n",
            "15/15 [==============================] - 6s 405ms/step - loss: 0.4547 - acc: 0.8710 - val_loss: 0.4252 - val_acc: 0.8659\n",
            "Epoch 30/100\n",
            "15/15 [==============================] - 6s 402ms/step - loss: 0.5108 - acc: 0.8624 - val_loss: 0.4759 - val_acc: 0.8564\n",
            "Epoch 31/100\n",
            "15/15 [==============================] - 6s 406ms/step - loss: 0.4415 - acc: 0.8815 - val_loss: 0.4061 - val_acc: 0.8604\n",
            "Epoch 32/100\n",
            "15/15 [==============================] - 6s 399ms/step - loss: 0.4794 - acc: 0.8777 - val_loss: 0.4650 - val_acc: 0.8726\n",
            "Epoch 33/100\n",
            "15/15 [==============================] - 6s 404ms/step - loss: 0.3616 - acc: 0.8892 - val_loss: 0.6719 - val_acc: 0.8415\n",
            "Epoch 34/100\n",
            "15/15 [==============================] - 6s 404ms/step - loss: 0.3916 - acc: 0.8883 - val_loss: 0.2809 - val_acc: 0.8848\n",
            "Epoch 35/100\n",
            "15/15 [==============================] - 6s 405ms/step - loss: 0.4062 - acc: 0.8715 - val_loss: 0.6082 - val_acc: 0.8211\n",
            "Epoch 36/100\n",
            "15/15 [==============================] - 6s 403ms/step - loss: 0.7007 - acc: 0.8237 - val_loss: 0.6187 - val_acc: 0.8455\n",
            "Epoch 37/100\n",
            "15/15 [==============================] - 6s 418ms/step - loss: 0.4643 - acc: 0.8573 - val_loss: 0.4576 - val_acc: 0.8753\n",
            "Epoch 38/100\n",
            "15/15 [==============================] - 6s 394ms/step - loss: 0.5173 - acc: 0.8575 - val_loss: 0.4171 - val_acc: 0.8672\n",
            "Epoch 39/100\n",
            "15/15 [==============================] - 6s 423ms/step - loss: 0.5808 - acc: 0.8622 - val_loss: 0.4483 - val_acc: 0.8686\n",
            "Epoch 40/100\n",
            "15/15 [==============================] - 6s 410ms/step - loss: 0.4453 - acc: 0.8624 - val_loss: 0.3891 - val_acc: 0.8577\n",
            "Epoch 41/100\n",
            "15/15 [==============================] - 6s 410ms/step - loss: 0.3539 - acc: 0.8761 - val_loss: 0.3653 - val_acc: 0.8848\n",
            "Epoch 42/100\n",
            "15/15 [==============================] - 6s 406ms/step - loss: 0.3606 - acc: 0.8734 - val_loss: 0.4412 - val_acc: 0.8780\n",
            "Epoch 43/100\n",
            "15/15 [==============================] - 6s 409ms/step - loss: 0.5743 - acc: 0.8537 - val_loss: 0.5066 - val_acc: 0.8645\n",
            "Epoch 44/100\n",
            "15/15 [==============================] - 6s 404ms/step - loss: 0.5256 - acc: 0.8517 - val_loss: 0.4767 - val_acc: 0.8659\n",
            "Epoch 45/100\n",
            "15/15 [==============================] - 6s 389ms/step - loss: 0.4744 - acc: 0.8645 - val_loss: 0.4311 - val_acc: 0.8591\n",
            "Epoch 46/100\n",
            "15/15 [==============================] - 6s 424ms/step - loss: 0.4280 - acc: 0.8701 - val_loss: 0.3929 - val_acc: 0.8699\n",
            "Epoch 47/100\n",
            "15/15 [==============================] - 6s 402ms/step - loss: 0.4901 - acc: 0.8728 - val_loss: 0.5697 - val_acc: 0.8482\n",
            "Epoch 48/100\n",
            "15/15 [==============================] - 6s 401ms/step - loss: 0.4552 - acc: 0.8756 - val_loss: 0.5122 - val_acc: 0.8618\n",
            "Epoch 49/100\n",
            "15/15 [==============================] - 6s 407ms/step - loss: 0.3984 - acc: 0.8762 - val_loss: 0.4178 - val_acc: 0.8780\n",
            "Epoch 50/100\n",
            "15/15 [==============================] - 6s 404ms/step - loss: 0.5029 - acc: 0.8661 - val_loss: 0.4864 - val_acc: 0.8604\n",
            "Epoch 51/100\n",
            "15/15 [==============================] - 6s 401ms/step - loss: 0.4138 - acc: 0.8701 - val_loss: 0.3586 - val_acc: 0.8726\n",
            "Epoch 52/100\n",
            "15/15 [==============================] - 6s 414ms/step - loss: 0.3727 - acc: 0.8819 - val_loss: 0.4485 - val_acc: 0.8821\n",
            "Epoch 53/100\n",
            "15/15 [==============================] - 6s 389ms/step - loss: 0.4321 - acc: 0.8713 - val_loss: 0.4231 - val_acc: 0.8726\n",
            "Epoch 54/100\n",
            "15/15 [==============================] - 6s 418ms/step - loss: 0.3894 - acc: 0.8861 - val_loss: 0.4895 - val_acc: 0.8686\n",
            "Epoch 55/100\n",
            "15/15 [==============================] - 6s 382ms/step - loss: 0.4011 - acc: 0.8887 - val_loss: 0.3700 - val_acc: 0.8753\n",
            "Epoch 56/100\n",
            "15/15 [==============================] - 6s 420ms/step - loss: 0.3959 - acc: 0.8861 - val_loss: 0.3671 - val_acc: 0.8740\n",
            "Epoch 57/100\n",
            "15/15 [==============================] - 6s 411ms/step - loss: 0.4555 - acc: 0.8800 - val_loss: 0.4475 - val_acc: 0.8659\n",
            "Epoch 58/100\n",
            "15/15 [==============================] - 6s 389ms/step - loss: 0.4773 - acc: 0.8800 - val_loss: 0.4088 - val_acc: 0.8726\n",
            "Epoch 59/100\n",
            "15/15 [==============================] - 6s 400ms/step - loss: 0.4879 - acc: 0.8795 - val_loss: 0.3259 - val_acc: 0.8753\n",
            "Epoch 60/100\n",
            "15/15 [==============================] - 6s 414ms/step - loss: 0.4777 - acc: 0.8590 - val_loss: 0.5250 - val_acc: 0.8442\n",
            "Epoch 61/100\n",
            "15/15 [==============================] - 6s 403ms/step - loss: 0.5463 - acc: 0.8492 - val_loss: 0.5300 - val_acc: 0.8388\n",
            "Epoch 62/100\n",
            "15/15 [==============================] - 6s 390ms/step - loss: 0.5398 - acc: 0.8520 - val_loss: 0.7578 - val_acc: 0.8333\n",
            "Epoch 63/100\n",
            "15/15 [==============================] - 6s 415ms/step - loss: 0.4767 - acc: 0.8389 - val_loss: 0.5103 - val_acc: 0.8333\n",
            "Epoch 64/100\n",
            "15/15 [==============================] - 6s 400ms/step - loss: 0.6174 - acc: 0.8393 - val_loss: 0.5869 - val_acc: 0.8388\n",
            "Epoch 65/100\n",
            "15/15 [==============================] - 6s 400ms/step - loss: 0.5849 - acc: 0.8330 - val_loss: 0.5693 - val_acc: 0.8564\n",
            "Epoch 66/100\n",
            "15/15 [==============================] - 6s 408ms/step - loss: 0.6383 - acc: 0.8353 - val_loss: 1.0542 - val_acc: 0.7940\n",
            "Epoch 67/100\n",
            "15/15 [==============================] - 6s 419ms/step - loss: 0.6895 - acc: 0.8337 - val_loss: 0.7440 - val_acc: 0.8306\n",
            "Epoch 68/100\n",
            "15/15 [==============================] - 6s 388ms/step - loss: 0.6580 - acc: 0.8383 - val_loss: 0.6657 - val_acc: 0.8442\n",
            "Epoch 69/100\n",
            "15/15 [==============================] - 6s 423ms/step - loss: 0.6060 - acc: 0.8497 - val_loss: 0.5693 - val_acc: 0.8442\n",
            "Epoch 70/100\n",
            "15/15 [==============================] - 6s 380ms/step - loss: 0.6272 - acc: 0.8474 - val_loss: 0.7820 - val_acc: 0.8320\n",
            "Epoch 71/100\n",
            "15/15 [==============================] - 6s 402ms/step - loss: 0.5531 - acc: 0.8587 - val_loss: 0.5498 - val_acc: 0.8577\n",
            "Epoch 72/100\n",
            "15/15 [==============================] - 6s 405ms/step - loss: 0.5508 - acc: 0.8567 - val_loss: 0.4953 - val_acc: 0.8455\n",
            "Epoch 73/100\n",
            "15/15 [==============================] - 6s 403ms/step - loss: 0.4867 - acc: 0.8420 - val_loss: 0.4307 - val_acc: 0.8509\n",
            "Epoch 74/100\n",
            "15/15 [==============================] - 6s 407ms/step - loss: 0.5314 - acc: 0.8411 - val_loss: 0.6724 - val_acc: 0.8415\n",
            "Epoch 75/100\n",
            "15/15 [==============================] - 6s 420ms/step - loss: 0.6018 - acc: 0.8469 - val_loss: 0.5064 - val_acc: 0.8482\n",
            "Epoch 76/100\n",
            "15/15 [==============================] - 6s 407ms/step - loss: 0.6358 - acc: 0.8349 - val_loss: 0.6206 - val_acc: 0.8293\n",
            "Epoch 77/100\n",
            "15/15 [==============================] - 6s 405ms/step - loss: 0.6276 - acc: 0.8383 - val_loss: 0.5237 - val_acc: 0.8496\n",
            "Epoch 78/100\n",
            "15/15 [==============================] - 6s 402ms/step - loss: 0.4951 - acc: 0.8569 - val_loss: 0.5702 - val_acc: 0.8252\n",
            "Epoch 79/100\n",
            "15/15 [==============================] - 6s 403ms/step - loss: 0.5303 - acc: 0.8476 - val_loss: 0.3421 - val_acc: 0.8428\n",
            "Epoch 80/100\n",
            "15/15 [==============================] - 6s 403ms/step - loss: 0.4044 - acc: 0.8546 - val_loss: 0.4747 - val_acc: 0.8252\n",
            "Epoch 81/100\n",
            "15/15 [==============================] - 6s 402ms/step - loss: 0.4247 - acc: 0.8319 - val_loss: 0.3097 - val_acc: 0.8537\n",
            "Epoch 82/100\n",
            "15/15 [==============================] - 6s 419ms/step - loss: 0.3716 - acc: 0.8646 - val_loss: 0.3100 - val_acc: 0.8564\n",
            "Epoch 83/100\n",
            "15/15 [==============================] - 6s 377ms/step - loss: 0.3151 - acc: 0.8656 - val_loss: 0.2958 - val_acc: 0.8753\n",
            "Epoch 84/100\n",
            "15/15 [==============================] - 6s 401ms/step - loss: 0.2983 - acc: 0.8615 - val_loss: 0.3023 - val_acc: 0.8577\n",
            "Epoch 85/100\n",
            "15/15 [==============================] - 6s 415ms/step - loss: 0.2865 - acc: 0.8750 - val_loss: 0.2888 - val_acc: 0.8726\n",
            "Epoch 86/100\n",
            "15/15 [==============================] - 6s 383ms/step - loss: 0.2948 - acc: 0.8740 - val_loss: 0.2953 - val_acc: 0.8550\n",
            "Epoch 87/100\n",
            "15/15 [==============================] - 6s 407ms/step - loss: 0.2934 - acc: 0.8712 - val_loss: 0.2938 - val_acc: 0.8577\n",
            "Epoch 88/100\n",
            "15/15 [==============================] - 6s 403ms/step - loss: 0.2859 - acc: 0.8694 - val_loss: 0.2815 - val_acc: 0.8686\n",
            "Epoch 89/100\n",
            "15/15 [==============================] - 6s 390ms/step - loss: 0.2638 - acc: 0.8826 - val_loss: 0.2756 - val_acc: 0.8780\n",
            "Epoch 90/100\n",
            "15/15 [==============================] - 6s 418ms/step - loss: 0.2674 - acc: 0.8743 - val_loss: 0.2897 - val_acc: 0.8604\n",
            "Epoch 91/100\n",
            "15/15 [==============================] - 6s 382ms/step - loss: 0.2828 - acc: 0.8767 - val_loss: 0.2763 - val_acc: 0.8726\n",
            "Epoch 92/100\n",
            "15/15 [==============================] - 6s 414ms/step - loss: 0.2644 - acc: 0.8733 - val_loss: 0.2623 - val_acc: 0.8713\n",
            "Epoch 93/100\n",
            "15/15 [==============================] - 6s 399ms/step - loss: 0.2711 - acc: 0.8803 - val_loss: 0.2614 - val_acc: 0.8740\n",
            "Epoch 94/100\n",
            "15/15 [==============================] - 6s 401ms/step - loss: 0.2585 - acc: 0.8893 - val_loss: 0.2735 - val_acc: 0.8645\n",
            "Epoch 95/100\n",
            "15/15 [==============================] - 6s 389ms/step - loss: 0.2497 - acc: 0.8871 - val_loss: 0.2789 - val_acc: 0.8713\n",
            "Epoch 96/100\n",
            "15/15 [==============================] - 6s 411ms/step - loss: 0.2611 - acc: 0.8799 - val_loss: 0.2553 - val_acc: 0.8740\n",
            "Epoch 97/100\n",
            "15/15 [==============================] - 6s 395ms/step - loss: 0.2634 - acc: 0.8767 - val_loss: 0.2586 - val_acc: 0.8753\n",
            "Epoch 98/100\n",
            "15/15 [==============================] - 6s 402ms/step - loss: 0.2533 - acc: 0.8894 - val_loss: 0.2616 - val_acc: 0.8713\n",
            "Epoch 99/100\n",
            "15/15 [==============================] - 6s 397ms/step - loss: 0.2508 - acc: 0.8877 - val_loss: 0.2582 - val_acc: 0.8794\n",
            "Epoch 100/100\n",
            "15/15 [==============================] - 6s 401ms/step - loss: 0.2649 - acc: 0.8845 - val_loss: 0.2718 - val_acc: 0.8821\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6fdgPyH_A3Ih",
        "colab_type": "code",
        "outputId": "7e742cbd-9ee4-4ba3-ccd0-902a8b5c2362",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 545
        }
      },
      "source": [
        "acc = history.history['acc']\n",
        "val_acc = history.history['val_acc']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "epochs = range(1, len(acc) + 1)\n",
        "#Train and validation accuracy\n",
        "plt.plot(epochs, acc, 'b', label='Training accurarcy')\n",
        "plt.plot(epochs, val_acc, 'r', label='Validation accurarcy')\n",
        "plt.title('Training and Validation accurarcy')\n",
        "plt.legend()\n",
        "\n",
        "plt.figure()\n",
        "#Train and validation loss\n",
        "plt.plot(epochs, loss, 'b', label='Training loss')\n",
        "plt.plot(epochs, val_loss, 'r', label='Validation loss')\n",
        "plt.title('Training and Validation loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAEICAYAAABWJCMKAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\naQBQSimH+j9JwL/pLh9POwAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAEICAYAAABPgw/pAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nTNANwzDCBBN0wzCMMMEE3TAMI0z4fxviuReF9RamAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MAe4R-Xd0FxB",
        "colab_type": "code",
        "outputId": "1d9e7eeb-1585-42bd-b4cd-5198faa4636a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "print(\"[INFO] Calculating model accuracy\")\n",
        "scores = model.evaluate(x_test, y_test)\n",
        "print(f\"Test Accuracy: {scores[1]*100}\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[INFO] Calculating model accuracy\n",
            "123/123 [==============================] - 0s 3ms/step\n",
            "Test Accuracy: 88.21138167768959\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uiNoJ_ii0Hi3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}